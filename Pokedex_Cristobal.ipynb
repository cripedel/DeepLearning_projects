{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pokedex_Cristobal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "149w2Zu9z6lz8hYKTg-oY45TrWuAL3PFX",
      "authorship_tag": "ABX9TyMsmXWssWxfoIxlB19uDUOY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cripedel/DeepLearning_projects/blob/DeepLearning_projects/Pokedex_Cristobal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agd3ApcPba8u"
      },
      "source": [
        "POKEMON-Proyecto Pokedex\n",
        "\n",
        "Información y consejos:\n",
        "Desarrollo del algoritmo empleando Keras.\n",
        "• Subir datos a Google Drive y montar dicha unidad en Colab para acceder a los mismos.\n",
        "•Crear vector de etiquetas (y_label) a partir del nombre de los directorios en los que\n",
        "están contenidos los datos.\n",
        "• Re-escalar imágenes y normalizarlas (valores de pixels entre 0 y 1). División del\n",
        "conjunto de datos en training (80%) y validación (20%).\n",
        "• Debido al escaso número de muestras de cada clase será necesario el uso de la técnica\n",
        "de generación sintética de datos: Data augmentation.\n",
        "• Como primera aproximación se puede entrenar la arquitectura de red convolucional\n",
        "usada en la práctica 4 para clasificar el dataset CIFAR10.\n",
        "• A partir de los resultados obtenidos (benchmark) ir aumentando la profundidad de la\n",
        "red y quedarse con el modelo que presente los mejores resultados.\n",
        "• Re-entrenar arquitecturas de red ya existentes en la literatura. Comparar los\n",
        "resultados obtenidos con los registrados en el punto anterior.\n",
        "• Evaluar el modelo con nuevas imágenes que no se encuentren en el conjuntos de\n",
        "datos de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUf3e6nkbP7U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "52595b7d-d0ce-4c39-b970-d27ad2eb1045"
      },
      "source": [
        "#Importamos librerias\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Activation, Flatten, Dense, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "\n",
        "#Importamos datos\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "path_pokemon = '/content/drive/My Drive/Curso_DL_CFP/Proyecto_Pokedex/DatosPokedex/dataset'\n",
        "modeloentrenado = '/content/drive/My Drive/Curso_DL_CFP/Proyecto_Pokedex'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmYLnITwnNRs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ef24e9b-ed48-4c4d-be39-2afc39c1313b"
      },
      "source": [
        "!ls '/content/gdrive/My Drive/Curso_DL_CFP/Proyecto_Pokedex/DatosPokedex/dataset'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bulbasaur  charmander  mewtwo  pikachu\tsquirtle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GBpjCjyjqr5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6f6c972e-8305-4cdf-fb28-a106fd28672a"
      },
      "source": [
        "#Creacion de las etiquetas ,buscar info  ==> image data generator ,flow from directory\n",
        "\n",
        "datagen_train = ImageDataGenerator(rotation_range=int(180*0.1), width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True, validation_split=0.2)\n",
        "val_datagen = datagen_train.flow_from_directory(path_pokemon, batch_size=32,  target_size=(32,32), class_mode='categorical', subset='validation')\n",
        "\n",
        "\n",
        "train = train_datagen.flow_from_directory(\n",
        "        path_pokemon,\n",
        "        target_size=(32, 32),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "labels = list(train.class_indices.keys())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 230 images belonging to 5 classes.\n",
            "Found 1167 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CwYznDTwNy5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "85fcd59d-944e-4075-f9e9-ef3bf824e27a"
      },
      "source": [
        "#Creamos y ejecutamos la red\n",
        "def deep_CNN(width, height, depth, classes,batchNorm):\n",
        "  # Definimos el modo API Sequential y las dimensiones de la entrada (suponemos TF->\"channels last\")\n",
        "  \n",
        "  inputs = Input(shape=(height, width, depth)) #(X)\n",
        "  \n",
        "  # Definimos la arquitectura\n",
        "  # Primer set de capas CONV => RELU => CONV => RELU => POOL\n",
        "  x1 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(inputs) #(X)\n",
        "  if batchNorm: \n",
        "    x1 = BatchNormalization()(x1) #(X)\n",
        "  x1 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(x1) #(X)\n",
        "  if batchNorm:\n",
        "    x1 = BatchNormalization()(x1) #(X)\n",
        "  x1 = MaxPooling2D(pool_size=(2, 2))(x1) #(X)\n",
        "  x1 = Dropout(0.25)(x1) #(X)\n",
        "  \n",
        "  # Segundo set de capas CONV => RELU => CONV => RELU => POOL\n",
        "  x2 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(x1) #(X)\n",
        "  if batchNorm: #(X)\n",
        "    x2 = BatchNormalization()(x2) #(X)\n",
        "  x2 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(x2) #(X)\n",
        "  if batchNorm:\n",
        "    x2 = BatchNormalization()(x2) #(X)\n",
        "  x2 = MaxPooling2D(pool_size=(2, 2))(x2) #(X)\n",
        "  x2 = Dropout(0.25)(x2) #(X)\n",
        "  \n",
        "  # Primer (y único) set de capas FC => RELU\n",
        "  xfc = Flatten()(x2) #(X)\n",
        "  xfc = Dense(512, activation=\"relu\")(xfc) #(X)\n",
        "  if batchNorm:\n",
        "    xfc = BatchNormalization()(xfc) #(X)\n",
        "  xfc = Dropout(0.5)(xfc) #(X)\n",
        "  # Clasificador softmax\n",
        "  predictions = Dense(classes, activation=\"softmax\")(xfc) #(X)\n",
        "  \n",
        "  # Unimos las entradas y el modelo mediante la función Model con parámetros inputs y ouputs (Consultar la documentación)\n",
        "  model = Model(inputs=inputs, outputs=predictions) #(X)\n",
        "  \n",
        "  # La función debe devolver el modelo como salida           \n",
        "  return model\n",
        "\n",
        "\n",
        "model = deep_CNN(width=256, height=256, depth=3, classes=5, batchNorm=True) #(X)\n",
        "# Compilamos el modelo\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(lr=0.01, decay=0.01/50, momentum=0.9, nesterov=True), metrics=[\"accuracy\"]) #(X)\n",
        "\n",
        "# Entrenamiento de la red\n",
        "print(\"[INFO]: Entrenando la red...\")\n",
        "H = model.fit_generator(train, validation_data = val_datagen, epochs=50, verbose=1) #(X)\n",
        "\n",
        "# Evaluación del modelo\n",
        "print(\"[INFO]: Evaluando el modelo...\")\n",
        "# Efectuamos la predicción (empleamos el mismo valor de batch_size que en training)\n",
        "predictions = model.predict(val_datagen) #(X)\n",
        "# Sacamos el report para test\n",
        "print(classification_report(val_datagen.classes, predictions.argmax(axis=1), target_names=labels)) #(X)\n",
        "\n",
        "#guardamos el modelo en drive para usarlo despues\n",
        "#model.save(myModelPath+'model.pokedex.h5')\n",
        "\n",
        "# Gráficas\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 50), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, 50), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, 50), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, 50), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]: Entrenando la red...\n",
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:989: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-f35de5b881f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Entrenamiento de la red\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO]: Entrenando la red...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_datagen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Evaluación del modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[32,256,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_43/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[metrics_9/acc/Mean/_2175]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[32,256,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_43/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1ZRgP0NZqBj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "26242df6-476b-4e08-aaf4-5e995b58ae5f"
      },
      "source": [
        "!ls '/content/drive/My Drive/Curso_DL_CFP/Proyecto_Pokedex/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "charmander.jpg\tmewtwo.jpg\t\t\t     Pokedex_Cristobal.ipynb\n",
            "DatosPokedex\tNivel_Basico_Desarrollo_Pokedex.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScVGVtt4XYcY"
      },
      "source": [
        "modeloentrenado = '/content/drive/My Drive/Curso_DL_CFP/Proyecto_Pokedex/'\n",
        "model.save(modeloentrenado+'modelpokedex.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKH6aT8eHnfK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kyq4fQ0CwfZD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9e38fb74-e932-4f58-cbf9-1eeb4675ef3c"
      },
      "source": [
        "\n",
        "drive.mount('/content/gdrive')\n",
        "image =\"/content/gdrive/My Drive/Curso_DL_CFP/Proyecto_Pokedex/charmander.jpg\"\n",
        "\n",
        "def predict_image(image, model, gt_str):\n",
        "  # Creamos una copia sobre la que mostraremos el resultado (comando image.copy())\n",
        "  output = image.copy() #(X)\n",
        "  # Expandimos las dimensiones (32, 32, 3) a (1, 32, 32, 3)\n",
        "  image = np.expand_dims(image, axis=0) #(X)\n",
        "\n",
        "  # Clasificación de la imagen empleando el modelo\n",
        "  print(\"[INFO]: Clasificando imagen...\")\n",
        "  # Realizamos la predicción\n",
        "  proba = model.predict(image) #(X)\n",
        "  print(proba)\n",
        "  # Nos quedamos con la clase que presente una probabilidad mayor y buscamos la etiqueta en el vector labelNames\n",
        "  idx = np.argmax(proba) #(X)\n",
        "  label = labels[idx] #(X)\n",
        "  #gt = labelNames[testY[num_img][0]] #(X)\n",
        "  # En caso que en la variable gt_str no me pasen el string \"CIFAR10\" es que me estan pasando el string con la etiqueta\n",
        "  # Si ese es el caso almaceno el gt de ese String (esto nos valdrá para predecir imágenes que no sean del dataset CIFAR10)\n",
        "\n",
        "  gt = gt_str #(X)\n",
        "\n",
        "  # Mostrando imagen e información\n",
        "  label = \"Predicción: {} - Confianza: {:.2f}% - Ground Truth: {}\".format(label, proba[0][idx] * 100, gt)\n",
        "  plt.imshow(output)\n",
        "  plt.title(label)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywzJLpD8NJ3N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "626d631a-c0f2-487e-a196-3175fdb50e60"
      },
      "source": [
        "\n",
        "drive.mount('/content/gdrive')\n",
        "imagetest =\"/content/gdrive/My Drive/Curso_DL_CFP/Proyecto_Pokedex/charmander.jpg\"\n",
        "\n",
        "img_test = cv2.imread(imagetest, cv2.IMREAD_COLOR) # Leo imagen con OPENCV\n",
        "img_test = cv2.cvtColor(img_test,cv2.COLOR_BGR2RGB) # Por defecto la carga en BGR, la convierto a RGB\n",
        "\n",
        "# Muestro información de la imagen y hago la predicción sacando resultados\n",
        "print(img_test.shape)\n",
        "plt.imshow(img_test)\n",
        "plt.title('my picture')\n",
        "plt.show()\n",
        "\n",
        "#escalo la imagen al mismo tamaño que las del modelo\n",
        "img_test = cv2.resize(img_test, (32,32))\n",
        "\n",
        "\n",
        "#if 'model' not in locals():\n",
        "  drive.mount('/content/drive') #(X)\n",
        "  model = model.load(modeloentrenado+'modelpokedex.h5')\n",
        "\n",
        "# Predecimos la imagen pasando como parámetros la imagen, el modelo\n",
        "predict_image(img_test, model, 'charmander') #(X)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-64-bbfe51c251a0>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    drive.mount('/content/drive') #(X)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    }
  ]
}